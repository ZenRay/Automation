services:
  mysql:
    image: mysql:8.0
    environment:
      MYSQL_ROOT_PASSWORD: ${MYSQL_ROOT_PASSWORD:-airflow}
      MYSQL_DATABASE: ${MYSQL_DATABASE:-airflow}
      MYSQL_USER: ${MYSQL_USER:-airflow}
      MYSQL_PASSWORD: ${MYSQL_PASSWORD:-airflow}
    volumes:
      - mysql-db-volume:/var/lib/mysql
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost"]
      timeout: 20s
      retries: 10
      start_period: 30s
    restart: always
    networks:
      - airflow-network
    dns:
      - 114.114.114.114
      - 8.8.8.8

  airflow:
    image: dispatcher-airflow:latest
    build:
      context: .
      dockerfile: Dockerfile
    env_file:
      - .env
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: mysql+pymysql://airflow:airflow@mysql:3306/airflow
      # 使用.env中的FERNET_KEY
      AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'
      AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
      AIRFLOW__API__AUTH_BACKENDS: 'airflow.api.auth.backend.basic_auth,airflow.api.auth.backend.session'
      AIRFLOW__CORE__DEFAULT_TIMEZONE: 'Asia/Shanghai'
      AIRFLOW__CORE__DAGS_FOLDER: '/opt/airflow/dags'
      AIRFLOW__CORE__PLUGINS_FOLDER: '/opt/airflow/plugins'
      AIRFLOW__LOGGING__BASE_LOG_FOLDER: '/opt/airflow/logs'
      AIRFLOW__LOGGING__LOGGING_LEVEL: 'INFO'
      AIRFLOW__WEBSERVER__EXPOSE_CONFIG: 'true'
      AIRFLOW__WEBSERVER__RBAC: 'true'
      AIRFLOW__WEBSERVER__DEFAULT_UI_TIMEZONE: 'Asia/Shanghai'
      AIRFLOW__SCHEDULER__SCHEDULER_HEARTBEAT_SEC: 10
      AIRFLOW__SCHEDULER__PARSING_PROCESSES: 4
      PYTHONPATH: "/opt/airflow:/opt/airflow/Automation:/opt/airflow/Automation/automation:/opt/airflow/Automation/dispatcher:/opt/airflow/models"
      _PIP_ADDITIONAL_REQUIREMENTS: ${_PIP_ADDITIONAL_REQUIREMENTS:-}
    volumes:
      - ~/data:/opt/airflow/data
      - ~/models:/opt/airflow/models
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
      - ./requirements.txt:/requirements.txt
      - ./etl_sentence:/opt/airflow/Automation/dispatcher/etl_sentence
      - ../Automation:/opt/airflow/Automation
      - ../data:/opt/airflow/data
      - ../models:/opt/airflow/models
    user: "airflow"
    ports:
      - "8080:8080"
      - "5678:5678"
    command: bash -c "
              airflow db init &&
              airflow db upgrade &&
              airflow users create --username admin --firstname Admin --lastname User --email admin@example.com --role Admin --password admin || true &&
              airflow scheduler & 
              airflow triggerer &
              airflow webserver"
    depends_on:
      mysql:
        condition: service_healthy
    restart: always
    networks:
      - airflow-network
    dns:
      - 114.114.114.114
      - 8.8.8.8
    deploy:
      resources:
        limits:
          cpus: '8'
          memory: 16G

networks:
  airflow-network:
    driver: bridge

volumes:
  mysql-db-volume:
